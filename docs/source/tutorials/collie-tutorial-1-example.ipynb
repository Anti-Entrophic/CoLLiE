{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561f4bc8-9d12-4c8e-bb90-b16e1dca4728",
   "metadata": {},
   "source": [
    "# 1. 真 - CoLLiE 快速上手\n",
    "\n",
    "> 1.1 &ensp; CoLLiE 的 运行准备\n",
    "> \n",
    "> 1.2 &ensp; 案例一：实现 Alpaca\n",
    "> \n",
    "> 1.3 &ensp; CoLLiE 的 框架兼容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ed4b7-3e59-466e-bb27-37f06626540f",
   "metadata": {},
   "source": [
    "## 1.1 &ensp; CoLLiE 的 运行准备\n",
    "\n",
    "&ensp; &ensp; 在上一节中，我们已经介绍了 CoLLiE 提出的背景、实现的功能 以及 包含的模块。通过上一节的叙述，想必大家已经可以配置好环境、成功地安装 CoLLiE，并且了解了 CoLLiE 的大致结构，遇到一些的功能需求可以找到对应的代码文件，尝试自行了解相关功能是如何实现的了。\n",
    "\n",
    "&ensp; &ensp; 在这一节中，我们将介绍 **CoLLiE 的使用流程** 以及 **基础模块的使用**，包括 **Config**、**Dataset**、**Evaluator**、**Trainer**。而正所谓实践出真知，在详细介绍上述模块的使用细节与基础原理前，本小节将先通过一个 CoLLiE 的使用案例，告诉大家 CoLLiE 是如何使用、相关代码是如何运行起来的；接着在后续小节中，详细介绍各个部分代码的运行原理、对应模块的使用细节。\n",
    "\n",
    "&ensp; &ensp; 多少显卡 多少模型 如何配置，按照2048长计算显卡需要数量，\n",
    "\n",
    "| 模型-大小 | A800<br />全量参数微调 | A800<br />显存高效微调 | RTX 3090<br />全量参数微调 | RTX 3090<br />显存高效微调 |\n",
    "|:----|:----:|:----:|:----:|:----:|\n",
    "| LLaMA-7B | 3 | 1 | 8 | 1 |\n",
    "| LLaMA-13B | 5 | 1 | 16 | 2 |\n",
    "| LLaMA-30B | 12 | 1 | 48 | 4 |\n",
    "| LLaMA-65B | 25 | 2 | 96 | 8 |\n",
    "| LLaMA2-7B | 3 | 1 | 8 | 1 |\n",
    "| LLaMA2-13B | 5 | 1 | 16 | 4 |\n",
    "| LLaMA2-70B | 27 | 2 | 104 | 8 |\n",
    "| IntermLM-7B | 3 | 1 | 8 | 1 |\n",
    "| ChatGLM-6B | 3 | 1 | 8 | 1 |\n",
    "| ChatGLM2-6B | 3 | 1 | 8 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1959a-0e02-42ce-872b-f785051c69eb",
   "metadata": {},
   "source": [
    "## 1.2 &ensp; 案例一：实现 Alpaca\n",
    "\n",
    "&ensp; &ensp; 解决alpaca任务 能跑通 一个例子，一个使用CoLLie对LLaMA基座进行全参量Instruct Tuning，从而得到Alpaca的实例。\n",
    "\n",
    "``` python\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from transformers import LlamaTokenizer\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "\n",
    "from collie.config import CollieConfig\n",
    "\n",
    "from collie.data import CollieDatasetForTraining\n",
    "from collie.data import CollieDataLoader\n",
    "\n",
    "from collie.controller.trainer import Trainer\n",
    "from collie.controller.evaluator import EvaluatorForPerplexity, EvaluatorForGeneration\n",
    "\n",
    "from collie.models.llama.model import LlamaForCausalLM\n",
    "from collie.utils.monitor import StepTimeMonitor, TGSMonitor, MemoryMonitor, LossMonitor, EvalMonitor\n",
    "from collie.metrics import DecodeMetric, PPLMetric, BleuMetric\n",
    "from collie.module import GPTLMLoss\n",
    "```\n",
    "\n",
    "解释\n",
    "\n",
    "``` python\n",
    "# 1. 设置路径\n",
    "# 1.1 预训练模型路径\n",
    "pretrained_model = 'decapoda-research/llama-7b-hf'\n",
    "# 1.2 数据集路径\n",
    "data_path = 'alpaca.json'\n",
    "# 1.3 Eval的decode结果保存路径\n",
    "save_path = './result'\n",
    "```\n",
    "\n",
    "解释\n",
    "\n",
    "``` python\n",
    "# 2. 设置配置\n",
    "# 2.1 加载配置\n",
    "config = CollieConfig.from_pretrained(pretrained_model)\n",
    "# 2.2 添加配置\n",
    "config.tp_size = 2\n",
    "config.dp_size = 2\n",
    "config.pp_size = 1\n",
    "config.train_epochs = 1\n",
    "config.train_micro_batch_size = 8\n",
    "config.eval_batch_size = 32\n",
    "config.eval_per_n_steps = 100\n",
    "config.ds_config = {\n",
    "    \"fp16\": {\"enabled\": True},\n",
    "    \"monitor_config\": {\n",
    "        \"enabled\": True,\n",
    "        \"tag\": \"sophia_alpaca\",\n",
    "        \"csv_monitor\": {\n",
    "            \"enabled\": True,\n",
    "            \"output_path\": \"./ds_logs/\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "解释\n",
    "\n",
    "``` python\n",
    "# 3. 设置tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(pretrained_model, padding_side=\"left\")\n",
    "\n",
    "# 4. 加载数据集\n",
    "dataset = CollieDatasetForTraining.from_json(data_path, tokenizer=tokenizer)\n",
    "train_dataset = dataset[:-32]\n",
    "eval_dataset = dataset[-32:]\n",
    "\n",
    "# 5. 加载预训练模型\n",
    "model = LlamaForCausalLM.from_config(config)\n",
    "```\n",
    "\n",
    "解释\n",
    "\n",
    "``` python\n",
    "# 6. 设置优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 7. 添加监视器\n",
    "monitors = [\n",
    "    StepTimeMonitor(config),\n",
    "    TGSMonitor(config),\n",
    "    MemoryMonitor(config),\n",
    "    LossMonitor(config),\n",
    "    EvalMonitor(config)\n",
    "]\n",
    "\n",
    "# 8. 添加Evaluator\n",
    "evaluator_ppl = EvaluatorForPerplexity(\n",
    "    model = model,\n",
    "    config = config,\n",
    "    dataset = eval_dataset,\n",
    "    monitors = [\n",
    "        EvalMonitor(config)\n",
    "    ],\n",
    "    metrics = {\n",
    "        'ppl': PPLMetric()\n",
    "    }\n",
    ")\n",
    "evaluator_decode = EvaluatorForGeneration(\n",
    "    model = model,\n",
    "    config = config,\n",
    "    tokenizer = tokenizer,\n",
    "    dataset = eval_dataset,\n",
    "    monitors = [\n",
    "        EvalMonitor(config)\n",
    "    ],\n",
    "    metrics = {\n",
    "        'decode': DecodeMetric(save_to_file = True, save_path = save_path)\n",
    "    }\n",
    "\n",
    ")\n",
    "```\n",
    "\n",
    "解释\n",
    "\n",
    "``` python\n",
    "# 9. 实例化trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    config = config,\n",
    "    loss_fn = GPTLMLoss(-100),\n",
    "    optimizer = optimizer,\n",
    "    train_dataset = train_dataset,\n",
    "    monitors = monitors,\n",
    "    evaluators = [evaluator_ppl, evaluator_decode]\n",
    ")\n",
    "\n",
    "# 10. 训练/验证\n",
    "trainer.train()\n",
    "\n",
    "#  Command CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --rdzv_backend=c10d --rdzv_endpoint=localhost:29402 --nnodes=1 --nproc_per_node=4 train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141669f4-b224-43f3-83cb-2a59ba375300",
   "metadata": {},
   "source": [
    "## 1.3 &ensp; CoLLiE 的 框架兼容\n",
    "\n",
    "&ensp; &ensp; 保存下来 Transformers加载（突出好用 能兼容 而不是全能）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a241cc-cba4-4799-bdab-22e8f57b7fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
